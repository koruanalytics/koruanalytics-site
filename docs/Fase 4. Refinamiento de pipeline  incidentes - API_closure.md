# Acci√≥n de Cierre de Chat del Proyecto: OSINT Per√∫ 2026

## Metadatos del Chat
| Campo | Valor |
|-------|-------|
| **Nombre del proyecto** | OSINT Per√∫ 2026 - Sistema de Monitoreo de Incidentes de Seguridad |
| **Fecha de inicio del chat** | 2026-01-04 |
| **Fecha de cierre** | 2026-01-05 |
| **Duraci√≥n estimada** | 1 sesi√≥n intensiva |
| **Fase del proyecto** | Refinamiento Backend v2 |

---

## 1. RESUMEN EJECUTIVO

Sistema de monitoreo de incidentes de seguridad para las elecciones de Per√∫ 2026. Arquitectura Medallion (Bronze ‚Üí Silver ‚Üí Gold) con enriquecimiento LLM. Durante esta sesi√≥n se intent√≥ refinar el pipeline pero se introdujeron cambios que rompieron la estrategia original de ingesta multi-grupo. **El proyecto necesita restaurar la arquitectura de ingesta por grupos tem√°ticos (v3) que funcionaba correctamente.**

---

## 2. STACK TECNOL√ìGICO

| Categor√≠a | Tecnolog√≠a | Versi√≥n |
|-----------|------------|---------|
| Lenguaje | Python | 3.12 |
| Base de datos | DuckDB | - |
| LLM | Claude Haiku | claude-3-5-haiku-20241022 |
| API Noticias | NewsAPI.ai (EventRegistry) | - |
| Cloud (pendiente) | Azure | OpenAI, AI Search, Maps |
| IDE | VS Code | - |

---

## 3. ESTRUCTURA DEL PROYECTO

```
2026_Peru/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ newsapi_scope_peru_v3.yaml    # ‚úÖ SCOPE CORRECTO - 7 grupos tem√°ticos
‚îÇ   ‚îú‚îÄ‚îÄ newsapi_scope_peru_v4.yaml    # ‚ö†Ô∏è source_based - trae TODO
‚îÇ   ‚îú‚îÄ‚îÄ newsapi_scope_peru_v5.yaml    # ‚ùå ROTO - excede l√≠mite 15 keywords
‚îÇ   ‚îî‚îÄ‚îÄ settings.yaml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ newsapi_ai_ingest.py      # ‚ö†Ô∏è Necesita restaurar multi_query_by_group
‚îÇ   ‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalize_newsapi_ai.py   # üîÑ Actualizado con ingest_run_id
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dedupe_newsapi_ai_in_duckdb.py
‚îÇ   ‚îú‚îÄ‚îÄ enrichment/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_enrichment_pipeline.py # üîÑ Actualizado pero con bugs de esquema
‚îÇ   ‚îú‚îÄ‚îÄ classification/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_classifier.py
‚îÇ   ‚îî‚îÄ‚îÄ geoparse/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ daily_pipeline.py         # üîÑ Actualizado pero apunta a scope v5 roto
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_newsapi_ai_job.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ osint_dw.duckdb               # Base de datos principal
‚îÇ   ‚îî‚îÄ‚îÄ raw/newsapi_ai/               # JSONs crudos
‚îî‚îÄ‚îÄ .env                              # ANTHROPIC_API_KEY, NEWSAPI_KEY
```

---

## 4. ESTADO DE LAS TABLAS (DuckDB)

| Tabla | Filas | Estado | Descripci√≥n |
|-------|-------|--------|-------------|
| `stg_news_newsapi_ai` | ~250 | ‚úÖ Con datos | Staging original que funcionaba |
| `bronze_news` | 0 | ‚ùå Vaciada | Se vaci√≥ durante pruebas |
| `silver_news_enriched` | 0 | ‚ùå Vaciada | Se vaci√≥ durante pruebas |
| `gold_incidents` | 0 | ‚ùå Vaciada | Se vaci√≥ durante pruebas |
| `gold_daily_stats` | 0 | ‚ùå Vaciada | Se vaci√≥ durante pruebas |
| `dim_places_pe` | 1,893 | ‚úÖ Intacta | Gazetteer de Per√∫ |

---

## 5. EL PROBLEMA CR√çTICO

### Arquitectura Original (v3) - FUNCIONABA
```
newsapi_scope_peru_v3.yaml
‚îú‚îÄ‚îÄ strategy: multi_query_by_group
‚îú‚îÄ‚îÄ 7 grupos tem√°ticos (electoral, violencia_politica, violencia_comun, etc.)
‚îú‚îÄ‚îÄ Cada grupo: ‚â§15 keywords (respeta l√≠mite API)
‚îú‚îÄ‚îÄ 7 queries separadas al API
‚îú‚îÄ‚îÄ Deduplicaci√≥n entre grupos
‚îî‚îÄ‚îÄ Resultado: ~50-100 art√≠culos relevantes/d√≠a
```

### Lo que se rompi√≥ (v4/v5)
```
v4: source_based
‚îú‚îÄ‚îÄ Trae TODO de las 7 fuentes sin filtrar
‚îú‚îÄ‚îÄ ~500+ art√≠culos/d√≠a (mayor√≠a irrelevantes)
‚îî‚îÄ‚îÄ Desperdicio de tokens LLM

v5: source_keywords (ROTO)
‚îú‚îÄ‚îÄ Intenta meter 38 keywords en una query
‚îú‚îÄ‚îÄ ERROR: "Too many keywords (39), limit is 15"
‚îî‚îÄ‚îÄ 0 art√≠culos
```

---

## 6. ARCHIVOS QUE NECESITAN RESTAURACI√ìN

### 6.1 `src/ingestion/newsapi_ai_ingest.py`
**Problema:** La funci√≥n `_query_group()` existe pero no se usa cuando `strategy != "location_based"`

**Soluci√≥n necesaria:** 
- Restaurar/crear estrategia `multi_query_by_group`
- Iterar sobre `concept_groups` del scope v3
- Una query por grupo con sus keywords espec√≠ficos
- Deduplicar entre grupos

### 6.2 `scripts/core/daily_pipeline.py`
**Problema:** Apunta a `newsapi_scope_peru_v5.yaml` (roto)

**Soluci√≥n:** Cambiar a `newsapi_scope_peru_v3.yaml`

```python
SCOPE_PATH = "config/newsapi_scope_peru_v3.yaml"  # Restaurar v3
```

### 6.3 `src/enrichment/llm_enrichment_pipeline.py`
**Problema:** El INSERT a `silver_news_enriched` no coincide con el esquema de la tabla

**Esquema de silver (actual):**
- NO tiene `body` (correcto, no queremos el body completo)
- Tiene `modelo_llm` (no `llm_model`)
- Tiene `tokens_usados` (no `tokens_in`, `tokens_out`)
- Tiene `processed_at` (no `enriched_at`)

---

## 7. SCOPE V3 - LA REFERENCIA CORRECTA

```yaml
# config/newsapi_scope_peru_v3.yaml (FUNCIONAL)
strategy: multi_query_by_group  # ‚Üê CLAVE

scope:
  location_uri: http://en.wikipedia.org/wiki/Peru
  concept_groups:
    - group_id: electoral
      keywords_spa: [elecciones 2026, candidato presidencial, JNE, ONPE, ...]
    - group_id: violencia_politica
      keywords_spa: [ataque a candidato, amenaza politica, ...]
    - group_id: violencia_comun
      keywords_spa: [asesinato, homicidio, sicariato, secuestro, ...]
    - group_id: protestas
      keywords_spa: [protesta, manifestacion, paro, huelga, ...]
    - group_id: terrorismo
      keywords_spa: [sendero luminoso, terrorismo, VRAEM, ...]
    - group_id: desastres_naturales
      keywords_spa: [terremoto, sismo, inundacion, huayco, ...]
    - group_id: accidentes
      keywords_spa: [accidente de transito, incendio, explosion, ...]

query_strategy:
  mode: multi_query_by_group
  max_per_group: 100
  max_total: 500
```

---

## 8. FLUJO DE DATOS CORRECTO

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INGESTA (multi_query_by_group)                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Para cada grupo en concept_groups:                          ‚îÇ
‚îÇ   ‚Üí Query API con locationUri + keywords del grupo          ‚îÇ
‚îÇ   ‚Üí Guardar JSON en data/raw/                               ‚îÇ
‚îÇ ‚Üí Deduplicar entre grupos (por URI)                         ‚îÇ
‚îÇ ‚Üí Normalizar a parquet                                      ‚îÇ
‚îÇ ‚Üí Cargar a bronze_news                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ENRIQUECIMIENTO LLM (Bronze ‚Üí Silver)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Para cada art√≠culo en bronze (no procesado):                ‚îÇ
‚îÇ   ‚Üí Enviar title + body a Claude Haiku                      ‚îÇ
‚îÇ   ‚Üí Extraer: tipo_evento, v√≠ctimas, geo, resumen            ‚îÇ
‚îÇ   ‚Üí Insertar en silver_news_enriched                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PROMOCI√ìN A GOLD (Silver ‚Üí Gold)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Filtrar:                                                    ‚îÇ
‚îÇ   - es_relevante = TRUE                                     ‚îÇ
‚îÇ   - es_internacional = FALSE                                ‚îÇ
‚îÇ   - es_resumen = FALSE                                      ‚îÇ
‚îÇ   - tipo_evento != 'no_relevante'                           ‚îÇ
‚îÇ ‚Üí Deduplicar eventos similares                              ‚îÇ
‚îÇ ‚Üí Insertar en gold_incidents                                ‚îÇ
‚îÇ ‚Üí Generar gold_daily_stats                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 9. MEJORAS IMPLEMENTADAS (CONSERVAR)

### 9.1 Prompt LLM mejorado
- Detecta `es_internacional` (eventos fuera de Per√∫)
- Detecta `es_resumen` (art√≠culos de estad√≠sticas/conmemoraci√≥n)
- Res√∫menes de 3-4 oraciones (no 1-2)
- Campo `pais_evento`

### 9.2 QualityValidator
- Patrones regex para detectar res√∫menes
- Detecci√≥n de art√≠culos internacionales
- Deduplicaci√≥n por similitud de t√≠tulo

### 9.3 Filtros en build_gold_incidents()
- Excluye no_relevante, internacionales, res√∫menes
- Deduplicaci√≥n de eventos (mantiene el de m√°s v√≠ctimas)

### 9.4 Columnas nuevas en silver
- `es_internacional` (BOOLEAN)
- `es_resumen` (BOOLEAN)
- `pais_evento` (VARCHAR)

---

## 10. PR√ìXIMOS PASOS (PRIORIZADO)

### Alta Prioridad
1. **[INMEDIATO]** Restaurar estrategia `multi_query_by_group` en `newsapi_ai_ingest.py`
2. **[INMEDIATO]** Cambiar `daily_pipeline.py` para usar scope v3
3. **[INMEDIATO]** Arreglar INSERT en `llm_enrichment_pipeline.py` para coincidir con esquema silver

### Media Prioridad
4. **[DESPU√âS]** Reingestar desde 2026-01-01 con estrategia correcta
5. **[DESPU√âS]** Procesar con LLM y verificar calidad
6. **[DESPU√âS]** Hacer commit de todo el trabajo

### Baja Prioridad
7. **[FUTURO]** Migraci√≥n a Azure
8. **[FUTURO]** Frontend con Power BI + ArcGIS

---

## 11. COMANDOS √öTILES

```bash
# Ver estado de tablas
python -m src.enrichment.llm_enrichment_pipeline --status

# Ver datos en staging (que funcionaba)
python -c "import duckdb; con=duckdb.connect('data/osint_dw.duckdb'); print(con.execute('SELECT COUNT(*) FROM stg_news_newsapi_ai').fetchone())"

# Ver distribuci√≥n por fecha en staging
python -c "import duckdb; con=duckdb.connect('data/osint_dw.duckdb'); print(con.execute('SELECT DATE(published_at) as fecha, COUNT(*) as n FROM stg_news_newsapi_ai GROUP BY 1 ORDER BY 1 DESC').fetchdf())"

# Vaciar tablas para reiniciar
python -c "import duckdb; con=duckdb.connect('data/osint_dw.duckdb'); con.execute('DELETE FROM gold_daily_stats'); con.execute('DELETE FROM gold_incidents'); con.execute('DELETE FROM silver_news_enriched'); con.execute('DELETE FROM bronze_news'); print('Tablas vaciadas')"
```

---

## 12. VARIABLES DE ENTORNO REQUERIDAS

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-...
NEWSAPI_KEY=...  # Tambi√©n: NEWSAPI_AI_KEY o EVENTREGISTRY_API_KEY
```

---

## 13. L√çMITES DEL API (CR√çTICO)

| L√≠mite | Valor | Notas |
|--------|-------|-------|
| Keywords por query | 15 | Tu suscripci√≥n actual |
| Art√≠culos por query | ~100-500 | Depende del plan |

**Por eso la estrategia multi_query_by_group es esencial:** divide los ~100 keywords en 7 grupos de ~15 cada uno.

---

## 14. NOTAS PARA EL PR√ìXIMO CHAT

### ‚ö†Ô∏è Trampas / Cosas que cost√≥ descubrir
- El scope v4 (source_based) trae TODO sin filtrar ‚Üí demasiados art√≠culos irrelevantes
- El scope v5 (source_keywords) rompe porque excede 15 keywords
- El esquema de silver_news_enriched NO tiene columna `body`
- PowerShell tiene problemas con comillas en comandos Python inline

### üí° Tips importantes
- Usar scope v3 con estrategia `multi_query_by_group`
- Cada grupo debe tener ‚â§15 keywords
- El LLM trabaja sobre bronze (que s√≠ tiene body)
- Silver solo guarda resumen, no body completo

### üìù Archivos a restaurar desde uploads/contexto
- La l√≥gica de `_query_group()` iterando sobre `concept_groups`
- El INSERT correcto alineado con esquema de silver

---

## 15. PROMPT DE CONTINUACI√ìN

> **Copia esto al inicio del nuevo chat:**
>
> ```
> Contin√∫o el proyecto "OSINT Per√∫ 2026".
> 
> Stack: Python 3.12 + DuckDB + Claude Haiku + NewsAPI.ai
> IDE: VS Code
> 
> Estado actual: Pipeline roto - necesita restaurar estrategia multi_query_by_group
> 
> Problema: Se cambi√≥ de estrategia de ingesta (v3 grupos ‚Üí v4/v5) y se rompi√≥.
> La estrategia correcta est√° en newsapi_scope_peru_v3.yaml con 7 grupos tem√°ticos.
> 
> Siguiente tarea: 
> 1. Restaurar estrategia multi_query_by_group en newsapi_ai_ingest.py
> 2. Alinear INSERT de silver con esquema de tabla
> 3. Reingestar desde 2026-01-01
> 
> Adjunto documento de contexto con detalles completos.
> ```

---

## Historial de Sesiones

| Sesi√≥n | Fecha | Enfoque principal | Resultado |
|--------|-------|-------------------|-----------|
| Refinamiento 1 | 2026-01-03/04 | Arquitectura Medallion, LLM pipeline | ‚úÖ Funcionando |
| Refinamiento 2 | 2026-01-04/05 | Limpieza gold, mejoras prompt | ‚ö†Ô∏è Rompi√≥ ingesta |

---

*Documento generado: 2026-01-05*
