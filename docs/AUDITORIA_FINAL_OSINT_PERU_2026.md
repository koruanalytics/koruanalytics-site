# üîç AUDITOR√çA FINAL CONSOLIDADA - OSINT PER√ö 2026

**Fecha:** 2026-01-05  
**Versi√≥n:** 1.0  
**Prop√≥sito:** Documento de referencia para continuar desarrollo en chats independientes

---

## üìã √çNDICE

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Evoluci√≥n del Proyecto (Fases 0-4)](#2-evoluci√≥n-del-proyecto)
3. [Estado Actual del C√≥digo](#3-estado-actual-del-c√≥digo)
4. [Problema Central: Estrategia de Ingesta](#4-problema-central-estrategia-de-ingesta)
5. [Arquitectura de Datos](#5-arquitectura-de-datos)
6. [Paquetes de Trabajo Independientes](#6-paquetes-de-trabajo-independientes)
7. [Inventario de Archivos](#7-inventario-de-archivos)
8. [Stack Tecnol√≥gico](#8-stack-tecnol√≥gico)
9. [Configuraci√≥n y Variables](#9-configuraci√≥n-y-variables)

---

## 1. RESUMEN EJECUTIVO

### Qu√© es el proyecto
Sistema de monitoreo de incidentes de seguridad para las elecciones de Per√∫ 2026. Pipeline automatizado que ingesta noticias de 7 medios peruanos, clasifica con LLM, y genera inteligencia sobre violencia, protestas, terrorismo y otros eventos relevantes.

### Estado actual
- ‚úÖ **Arquitectura Medallion implementada** (Bronze ‚Üí Silver ‚Üí Gold)
- ‚úÖ **Clasificaci√≥n LLM funcionando** (Claude Haiku, 14 categor√≠as)
- ‚ö†Ô∏è **Estrategia de ingesta rota** (v5 excede l√≠mite API de 15 keywords)
- ‚ö†Ô∏è **Dos pipelines coexisten** (legacy ACLED vs Medallion LLM)
- ‚ö†Ô∏è **Schema.py desactualizado** (no define tablas Medallion)

### M√©tricas del √∫ltimo run exitoso
| M√©trica | Valor |
|---------|-------|
| Art√≠culos procesados | 722 |
| Incidentes relevantes | 210 (29%) |
| Ruido filtrado | 512 (71%) |
| Muertos registrados | 408 |
| Heridos registrados | 2,046 |
| Costo LLM | ~$0.50 USD |

---

## 2. EVOLUCI√ìN DEL PROYECTO

### Fase 0: Setup Inicial
- Arquitectura base con DuckDB
- Ingesta con location-based queries (6 art√≠culos/d√≠a - muy bajo)
- Clasificaci√≥n rule-based ACLED (90% ruido)

### Fase 2: An√°lisis de Cobertura API
- Dise√±o de estrategia de **12 grupos tem√°ticos** para sortear l√≠mite de 15 keywords
- Cada grupo hace una query independiente con ‚â§15 keywords
- **Esta era la soluci√≥n correcta** para el problema del API

### Fase 3: Arquitectura Medallion + LLM
- Cambio a **source_based** (7 fuentes peruanas): 6‚Üí650 art√≠culos/d√≠a
- Implementaci√≥n de clasificaci√≥n con **Claude Haiku**: 90%‚Üí29% ruido
- Creaci√≥n de **Bronze/Silver/Gold** tables
- Pipeline LLM funcionando correctamente
- **Problema:** source_based trae TODO, gastando tokens LLM en ruido

### Fase 4: Refinamiento (ROMPI√ì COSAS)
- Intento de crear v5 con source_keywords
- **ERROR:** v5 pone 38 keywords en una query (l√≠mite es 15)
- Tablas Bronze/Silver/Gold vaciadas durante pruebas
- Pipeline qued√≥ en estado inconsistente

### L√≠nea Temporal de Estrategias de Ingesta

```
v3: multi_query_by_group     ‚úÖ FUNCIONABA
    ‚îî‚îÄ 7 grupos √ó ‚â§15 keywords cada uno = 7 queries al API
    ‚îî‚îÄ ~50-100 art√≠culos relevantes/d√≠a
    ‚îî‚îÄ Respeta l√≠mite del API
    
v4: source_based             ‚ö†Ô∏è FUNCIONA PERO INEFICIENTE  
    ‚îî‚îÄ 1 query: 7 fuentes, SIN filtro de keywords
    ‚îî‚îÄ ~650 art√≠culos/d√≠a (70% ruido)
    ‚îî‚îÄ Desperdicia tokens LLM en clasificar ruido
    
v5: source_keywords          ‚ùå ROTO
    ‚îî‚îÄ 1 query: 7 fuentes + 38 keywords
    ‚îî‚îÄ ERROR: excede l√≠mite de 15 keywords
    ‚îî‚îÄ 0 art√≠culos
```

---

## 3. ESTADO ACTUAL DEL C√ìDIGO

### Pipelines en Conflicto

| Pipeline | Entry Point | Tablas | Estado |
|----------|-------------|--------|--------|
| **Legacy (ACLED)** | `run_newsapi_ai_job.py` | stg_news_newsapi_ai ‚Üí stg_incidents_extracted ‚Üí fct_incidents | Obsoleto pero presente |
| **Medallion (LLM)** | `daily_pipeline.py` | bronze_news ‚Üí silver_news_enriched ‚Üí gold_incidents | Activo pero roto (v5) |

### Scripts Activos vs Obsoletos

**ACTIVOS (usar):**
```
scripts/core/daily_pipeline.py          # Pipeline principal Medallion
src/enrichment/llm_enrichment_pipeline.py   # Bronze‚ÜíSilver‚ÜíGold
src/ingestion/newsapi_ai_ingest.py      # Ingestor (necesita fix)
src/processing/normalize_newsapi_ai.py  # JSON‚ÜíParquet
```

**OBSOLETOS (mover a _legacy):**
```
scripts/core/run_newsapi_ai_job.py      # Usa pipeline ACLED
src/processing/load_newsapi_ai_to_dw.py # Carga a stg_news (legacy)
src/processing/dedupe_newsapi_ai_in_duckdb.py  # Dedupe legacy
src/incidents/extract_baseline.py       # Extracci√≥n ACLED
src/incidents/acled_rules.py            # Clasificaci√≥n rules
```

### Estado de Tablas en DuckDB

**Tablas Medallion (ACTIVAS):**
| Tabla | Estado | Rows (√∫ltimo conocido) |
|-------|--------|------------------------|
| bronze_news | ‚ö†Ô∏è Posiblemente vac√≠a | 722 antes de fase 4 |
| silver_news_enriched | ‚ö†Ô∏è Posiblemente vac√≠a | 722 antes de fase 4 |
| gold_incidents | ‚ö†Ô∏è Posiblemente vac√≠a | 210 antes de fase 4 |
| gold_daily_stats | ‚ö†Ô∏è Posiblemente vac√≠a | 31 antes de fase 4 |
| dim_places_pe | ‚úÖ Intacta | 1,893 |

**Tablas Legacy (ELIMINAR):**
```
stg_news_newsapi_ai, stg_news_newsapi_ai_dedup, stg_news_newsapi_ai_dedup_run,
stg_incidents_extracted, fct_incidents, fct_incidents_curated,
fct_incident_places, map_incident_place, map_incident_place_v2,
stg_incident_place_candidates, curation_incident_overrides, incidents_test, stg_news_dummy
```

---

## 4. PROBLEMA CENTRAL: ESTRATEGIA DE INGESTA

### El Dilema
NewsAPI.ai tiene **l√≠mite de 15 keywords por query**. El proyecto necesita ~100 keywords para cubrir todas las categor√≠as.

### Soluciones Intentadas

| Estrategia | C√≥mo funciona | Resultado |
|------------|---------------|-----------|
| **v3: multi_query_by_group** | 7 queries separadas, cada una con ‚â§15 keywords | ‚úÖ Funciona, ~100 art√≠culos relevantes/d√≠a |
| **v4: source_based** | 1 query con 7 fuentes, sin keywords | ‚ö†Ô∏è Funciona pero trae 650 art√≠culos (70% ruido) |
| **v5: source_keywords** | 1 query con fuentes + todos los keywords | ‚ùå Rompe API (>15 keywords) |

### Soluci√≥n Recomendada: H√≠brido v3+v5

```yaml
# Propuesta: source_keywords POR GRUPO
strategy: source_keywords_by_group

groups:
  - group_id: violencia
    source_uris: [elcomercio.pe, larepublica.pe, ...]
    keywords: [asesinato, homicidio, sicariato, ...]  # ‚â§15
    
  - group_id: electoral  
    source_uris: [elcomercio.pe, larepublica.pe, ...]
    keywords: [elecciones, candidato, JNE, ONPE, ...]  # ‚â§15
    
  # ... 5-7 grupos m√°s
```

**Beneficios:**
- ‚úÖ Respeta l√≠mite de 15 keywords por query
- ‚úÖ Filtra en ingesta (menos tokens LLM)
- ‚úÖ Cobertura completa de temas
- ‚úÖ Combina lo mejor de v3 y v5

---

## 5. ARQUITECTURA DE DATOS

### Flujo Correcto (Medallion)

```
NewsAPI.ai
    ‚Üì [7 queries por grupo tem√°tico]
data/raw/*.json
    ‚Üì [normalize_newsapi_ai.py]
data/interim/*.parquet
    ‚Üì [load_to_bronze_with_dedupe]
bronze_news (DuckDB)
    ‚Üì [llm_enrichment_pipeline.py + Claude Haiku]
silver_news_enriched (DuckDB)
    ‚Üì [build_gold_incidents - filtros de calidad]
gold_incidents + gold_daily_stats (DuckDB)
```

### Esquema de Tablas Medallion

**bronze_news:**
- incident_id, title, body, url, published_at
- source, source_title, language
- ingest_run_id, retrieved_at

**silver_news_enriched:**
- bronze_id (FK), es_relevante, es_internacional, es_resumen
- tipo_evento, subtipo, muertos, heridos
- departamento, provincia, distrito
- resumen_es, resumen_en, sentiment, confianza
- modelo_llm, tokens_usados, processed_at

**gold_incidents:**
- incident_id, bronze_id, fecha_incidente
- tipo_evento, subtipo, muertos, heridos
- departamento, provincia, distrito, lat, lon
- titulo, resumen, source_name, url
- created_at

---

## 6. PAQUETES DE TRABAJO INDEPENDIENTES

### üì¶ PAQUETE 1: Restaurar Estrategia de Ingesta
**Prioridad:** üî¥ CR√çTICA  
**Estimaci√≥n:** 2-3 horas  
**Dependencias:** Ninguna

**Tareas:**
1. Crear/restaurar estrategia `source_keywords_by_group` en `newsapi_ai_ingest.py`
2. Crear `newsapi_scope_peru_v6.yaml` con grupos + keywords (‚â§15 por grupo)
3. Actualizar `daily_pipeline.py` para usar v6
4. Testear ingesta de 1 d√≠a

**Archivos a modificar:**
- `src/ingestion/newsapi_ai_ingest.py`
- `config/newsapi_scope_peru_v6.yaml` (nuevo)
- `scripts/core/daily_pipeline.py`

**Criterio de √©xito:**
- Ingesta ejecuta sin errores
- ~50-150 art√≠culos por d√≠a
- Cada query usa ‚â§15 keywords

---

### üì¶ PAQUETE 2: Consolidar Schema y Limpiar BD
**Prioridad:** üü° ALTA  
**Estimaci√≥n:** 1-2 horas  
**Dependencias:** Ninguna (puede ir en paralelo con P1)

**Tareas:**
1. A√±adir DDLs de tablas Medallion a `src/db/schema.py`
2. Crear script `init_medallion_tables.py`
3. Eliminar tablas legacy de la BD
4. Documentar schema final

**Archivos a modificar:**
- `src/db/schema.py`
- `scripts/utils/init_medallion_tables.py` (nuevo)

**Criterio de √©xito:**
- Schema.py es fuente √∫nica de verdad
- BD solo tiene tablas activas
- Script de inicializaci√≥n funciona

---

### üì¶ PAQUETE 3: Limpiar C√≥digo Legacy
**Prioridad:** üü° ALTA  
**Estimaci√≥n:** 1 hora  
**Dependencias:** P1, P2 completados

**Tareas:**
1. Mover scripts obsoletos a `scripts/_legacy/`
2. Mover m√≥dulos obsoletos a `src/_legacy/`
3. Actualizar imports si hay dependencias
4. Verificar que pipeline sigue funcionando

**Archivos a mover:**
```
‚Üí scripts/_legacy/:
  - run_newsapi_ai_job.py
  - build_fct_incidents.py
  - run_incident_extract.py

‚Üí src/_legacy/:
  - processing/load_newsapi_ai_to_dw.py
  - processing/dedupe_newsapi_ai_in_duckdb.py
  - incidents/extract_baseline.py
  - incidents/acled_rules.py
```

---

### üì¶ PAQUETE 4: Fix Pipeline LLM
**Prioridad:** üü° ALTA  
**Estimaci√≥n:** 1-2 horas  
**Dependencias:** P1 completado

**Tareas:**
1. Verificar/corregir INSERT en `llm_enrichment_pipeline.py` vs esquema silver
2. A√±adir validaci√≥n para evitar `no_relevante` en gold
3. Mejorar detecci√≥n de art√≠culos de resumen
4. Testear procesamiento de 100 art√≠culos

**Archivos a modificar:**
- `src/enrichment/llm_enrichment_pipeline.py`

**Criterio de √©xito:**
- INSERT alineado con esquema
- 0 registros `no_relevante` en gold
- Art√≠culos de resumen marcados correctamente

---

### üì¶ PAQUETE 5: Re-ingesta Hist√≥rica
**Prioridad:** üü¢ MEDIA  
**Estimaci√≥n:** 2-4 horas (incluye tiempo de ejecuci√≥n)  
**Dependencias:** P1, P4 completados

**Tareas:**
1. Vaciar tablas Medallion (backup primero)
2. Ingestar desde 2025-12-15 hasta hoy
3. Procesar con LLM
4. Validar calidad de datos

**Comandos:**
```powershell
# Backup
Copy-Item data/osint_dw.duckdb data/osint_dw_backup_pre_reingesta.duckdb

# Vaciar
python -c "import duckdb; con=duckdb.connect('data/osint_dw.duckdb'); [con.execute(f'DELETE FROM {t}') for t in ['gold_daily_stats','gold_incidents','silver_news_enriched','bronze_news']]"

# Ingestar
python -m scripts.core.daily_pipeline --full --date-start 2025-12-15 --date-end 2026-01-05
```

---

### üì¶ PAQUETE 6: Optimizar venv
**Prioridad:** üü¢ BAJA  
**Estimaci√≥n:** 30 min  
**Dependencias:** Ninguna

**Problema:** venv pesa 1.7GB con paquetes innecesarios (torch, spacy, transformers)

**Tareas:**
1. Generar `requirements-minimal.txt`
2. Documentar paquetes necesarios vs innecesarios
3. (Opcional) Recrear venv limpio

**Paquetes a eliminar:**
- torch (432MB) - No usado, clasificaci√≥n es via API
- spacy (85MB) - No usado
- transformers (87MB) - No usado
- sympy (66MB) - No usado

**Paquetes necesarios:**
- anthropic, duckdb, pandas, pyarrow, loguru
- pyyaml, python-dotenv, eventregistry
- requests

---

### üì¶ PAQUETE 7: Migraci√≥n Azure (Futuro)
**Prioridad:** ‚ö™ FUTURA  
**Estimaci√≥n:** 1-2 d√≠as  
**Dependencias:** P1-P5 completados, pipeline estable

**Tareas:**
1. Containerizar con Docker
2. Migrar DuckDB ‚Üí Azure PostgreSQL
3. Configurar Azure Functions para ejecuci√≥n diaria
4. Configurar Azure AI Search para RAG
5. Configurar monitoreo

---

## 7. INVENTARIO DE ARCHIVOS

### Configuraci√≥n
| Archivo | Estado | Notas |
|---------|--------|-------|
| `config/newsapi_scope_peru_v3.yaml` | ‚úÖ Referencia | Estrategia multi-grupo correcta |
| `config/newsapi_scope_peru_v4.yaml` | ‚ö†Ô∏è Funciona | Source-based (trae todo) |
| `config/newsapi_scope_peru_v5.yaml` | ‚ùå Roto | Excede 15 keywords |
| `config/settings.yaml` | ‚úÖ OK | Configuraci√≥n general |
| `.env` | ‚úÖ Requerido | ANTHROPIC_API_KEY, NEWSAPI_KEY |

### Scripts Core
| Archivo | Estado | Funci√≥n |
|---------|--------|---------|
| `scripts/core/daily_pipeline.py` | ‚ö†Ô∏è Fix scope | Pipeline principal |
| `scripts/core/run_newsapi_ai_job.py` | ‚ùå Legacy | Mover a _legacy |

### M√≥dulos Src
| Archivo | Estado | Funci√≥n |
|---------|--------|---------|
| `src/ingestion/newsapi_ai_ingest.py` | ‚ö†Ô∏è Fix estrategia | Ingestor |
| `src/enrichment/llm_enrichment_pipeline.py` | ‚ö†Ô∏è Fix INSERT | Pipeline LLM |
| `src/classification/llm_classifier.py` | ‚úÖ OK | Clasificador standalone |
| `src/processing/normalize_newsapi_ai.py` | ‚úÖ OK | Normalizaci√≥n |
| `src/db/schema.py` | ‚ö†Ô∏è Incompleto | A√±adir Medallion DDLs |

---

## 8. STACK TECNOL√ìGICO

| Categor√≠a | Tecnolog√≠a | Versi√≥n/Notas |
|-----------|------------|---------------|
| Lenguaje | Python | 3.12 |
| Base de datos | DuckDB | Arquitectura Medallion |
| LLM | Claude Haiku | claude-3-5-haiku-20241022 |
| API Noticias | NewsAPI.ai | EventRegistry client |
| Logging | loguru | Timestamps, rotation |
| Config | pyyaml, python-dotenv | .env + YAML |
| Cloud (futuro) | Azure | Functions, PostgreSQL, AI Search |
| IDE | VS Code | - |
| OS | Windows 10/11 | Task Scheduler para automation |

---

## 9. CONFIGURACI√ìN Y VARIABLES

### Variables de Entorno (.env)
```bash
# Requeridas
ANTHROPIC_API_KEY=sk-ant-api03-...
NEWSAPI_KEY=...                    # Tambi√©n: NEWSAPI_AI_KEY

# Opcionales (futuro Azure)
AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com/
AZURE_OPENAI_KEY=xxx
AZURE_STORAGE_CONNECTION_STRING=xxx
```

### Paths Importantes
```
data/osint_dw.duckdb              # BD principal
data/raw/newsapi_ai/              # JSONs crudos
data/interim/newsapi_ai/          # Parquets normalizados
config/geo/peru_gazetteer_full.csv # Gazetteer
logs/newsapi_ai/                  # Logs de ejecuci√≥n
```

### L√≠mites del API
| L√≠mite | Valor | Notas |
|--------|-------|-------|
| Keywords por query | **15** | CR√çTICO - causa del problema v5 |
| Art√≠culos por query | ~100-500 | Depende del plan |

---

## üìå PROMPT PARA INICIAR CHAT DE DESARROLLO

```
Contin√∫o el proyecto "OSINT Per√∫ 2026".

Stack: Python 3.12 + DuckDB + Claude Haiku + NewsAPI.ai
IDE: VS Code

CONTEXTO:
- Sistema de monitoreo de incidentes de seguridad para elecciones Per√∫ 2026
- Arquitectura Medallion (Bronze ‚Üí Silver ‚Üí Gold) con clasificaci√≥n LLM
- El proyecto tiene c√≥digo funcional pero necesita reparaciones

PROBLEMA PRINCIPAL:
La estrategia de ingesta est√° rota. NewsAPI.ai tiene l√≠mite de 15 keywords/query.
- v3 (multi_query_by_group) funcionaba con 7 grupos √ó ‚â§15 keywords
- v5 (source_keywords) pone 38 keywords en 1 query ‚Üí ERROR

PAQUETE DE TRABAJO: [ESPECIFICAR CUAL]

Adjunto: AUDITORIA_FINAL_OSINT_PERU_2026.md

¬øEmpezamos?
```

---

*Documento generado: 2026-01-05*  
*Auditor√≠a realizada sobre: ZIP del proyecto + documentos de cierre Fases 0-4*
